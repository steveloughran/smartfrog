<?xml version="1.0"?>
<project name="testharness" default="default">

<!--
/** (C) Copyright 1998-2007 Hewlett-Packard Development Company, LP

This library is free software; you can redistribute it and/or
modify it under the terms of the GNU Lesser General Public
License as published by the Free Software Foundation; either
version 2.1 of the License, or (at your option) any later version.

This library is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public
License along with this library; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

For more information: www.smartfrog.org

*/
-->

<description>
  This is the build file for the test harness for smartfrog.
  It depends on smartfrog being built in the directory tree
  ../smartfrog (override smartfrog.home to change),
  and with ../smartfrog/dist/lib/smartfrog.jar existing.
  It also needs junit3.8.1 or 3.8.2 or later in ANT_HOME/lib,
  and a recent copy of Xalan to turn the XML Reports into HTML.
  These reports are all placed in build/test/reports, incidentally.

  To run just one test, run the test target with the testcase property set to
  the full name of the test, e.g.
    -Dtestcase=org.smartfrog.test.unit.core.coreTest

  You can enable/disable unit tests by setting unit.tests to true or false;
  system tests by setting system.tests to true or false. By default both are enabled.

  Failing tests are those that we know fail, but don't want cruise control or
  other things to halt. To run them, set
  
  run.failing.tests=true

  In build.properties or -Drun.failing.tests=true on the command line

  Do not run the system tests outside a secure environment, unless
  you are running a daemon that is secure.

  The target "dist" creates a jar file in the dist/lib directory,
  that contains all the utility classes needed to deploy smartfrog
  programs as part of a unit test system. It is designed to be reusable
  when testing other components. The "published" target publishes this
  to the ivy repository


</description>

   <!-- override point -->
  <property file="build.properties" />
  <property name="ivy.enabled" value="true"/>
  <property name="system.tests" value="true" />
  <!-- this component keeps its test files in a different place from the
       rest, for historical reasons (i.e. it is nothing but test) -->
  <property name="test.src.dir" location="testcases" />

  <property name="root.dir" location=".."  />

  <!-- Import common stuff -->
 <!-- <import file="${root.dir}/common.xml"/>-->
  <import file="../common.xml"/>


  <!--the default target publishes then runs the test. Why so?
    so that even if the tests fail, downstream things can use the testharness-->
  <target name="default" depends="published,test" />

  <!-- ========================================================== -->
  <!-- Test settings                                              -->
  <!-- ========================================================== -->

  <target name="init" depends="common.init,use-smartfrog-tasks">

    <property name="test.smartfrog.classesdir" location="${test.classes.dir}"/>
    
    <!-- load in our runtime properties too, so we can use presence/absence of
         values as a cue -->
    <property file="${runtime.properties}" prefix="runtime" />
    <property name="services" value="org/smartfrog/services/" />
    <property name="unittests" value="org/smartfrog/test/unit/" />
    <property name="systemtests" value="org/smartfrog/test/system/" />
    <property name="processtests" value="org/smartfrog/test/process/"/>
    <property name="componenttests" value="${systemtests}components/" />
  </target>


  <!-- ========================================================== -->
  <!-- this is the gump entry point; it does packaging but not the tests -->
  <!-- ========================================================== -->
  <target name="gump"
          depends="dist,published"
          description="target for gump builds"
    />

  <!-- replace the normal test with a simple noop, because we will
      not have the test harness around in the early stages of the build -->
  <target name="assert-smartfrog-testharness" />

  <target name="package-tests" depends="rmi-tests,common.package-tests"
    description="create the JAR file for the tests"/>

  <!-- ========================================================== -->
  <!-- compile the RMI. This is separate from the other compile, so that unit
       tests dont depend on it -->
  <!-- ========================================================== -->
  <target name="rmi-tests"
    depends="compile-tests">
    <sf-rmic includesfile="rmitargets" 
      base="${test.classes.dir}"
      verify="true">
      <classpath refid="tests.compile.classpath"/>
    </sf-rmic>
  </target>

  <!-- ========================================================== -->
  <!-- conditionally start the daemon if one was not found already-->
  <!-- and do not complain if it could not start (or execution timed out) -->
  <!-- ========================================================== -->
  <target name="start-daemon-if-needed-with-logging"
    depends="use-smartfrog-tasks,probe-local-daemon,init-daemon-with-logging"
    unless="local.daemon.running">
    <start-logging-daemon/>
  </target>



  <!-- initialise the test run. this includes setting up the classpath and the running jar-->
  <target name="init-tests" depends="package-tests" >
    <!--A list of all tests that fail-->
    <!-- if you add a test here, file a bugrep against it in jira
      and refer to it in this list. That way we can track which tests
       fail and why
    -->
    <echo level="verbose">
      system.tests.enabled=${system.tests.enabled}
      run.failing.tests=${run.failing.tests}
      testcase=${testcase}
    </echo>
    <patternset id="teststhatfail">
      <exclude unless="run.failing.tests" name="${systemtests}/java/LibraryTest.*"/>
      <!--http://jira.smartfrog.org/jira/browse/SFOS-25-->
      <exclude name="${systemtests}/workflow/sequence/SequenceTest.*"
          unless="run.failing.tests" />
      <!-- 2006-10-18: steve_l commented out while still finishing off the component,
        so Cruise Control doesn't fail-->
      <exclude name="${systemtests}/assertions/testcompounds/TestCompoundsTest.*"
          unless="run.failing.tests" />
      <!-- SFOS-154; test failing on VMWare only. Possible race condition-->
      <exclude name="${systemtests}/workflow/parallel/ParallelAsyncTest.*"
          unless="run.failing.tests" />
    </patternset>

    <ivy:cachepath pathid="testhelpers.classpath" conf="test-helpers"
        xmlns:ivy="antlib:fr.jayasoft.ivy.ant" />
    <path id="testharness.daemon.classpath">
      <!--test running classpath-->
      <path refid="testhelpers.classpath"/>
      <!--everything in the smartfrog dir-->
      <fileset refid="smartfrog.lib.fileset"/>
      <!--the test classes-->
      <fileset file="${test.jar}" />
      <!--the target classes-->
      <fileset file="${target.jar}" />
    </path>
    <echo level="verbose" >
      testharness.daemon.classpath=${toString:testharness.daemon.classpath}
    </echo>
  </target>
  
  <!-- ========================================================== -->
  <!-- run the unit tests -->
  <!-- ========================================================== -->
  <target name="unit-tests" depends="init-tests"  unless="testcase"
    description="run unit tests">
    <sf-junit
           errorProperty="test.failed"
           failureProperty="test.failed"
           >
      <sysproperty key="test.smartfrog.classesdir"
          value="${test.smartfrog.classesdir}" />
      <syspropertyset >
        <propertyref prefix="runtime"/>
      </syspropertyset>       
      <syspropertyset >
        <propertyref prefix="smartfrog"/>
      </syspropertyset>  
      <classpath>
        <path refid="tests.run.classpath"/>
      </classpath>
      <batchtest todir="${test.data.dir}" if="unit.tests.enabled">
        <!-- bulk test case -->
        <fileset dir="${test.classes.dir}">
          <include name="${unittests}**/*Test.class" />
       </fileset>
      </batchtest>
    </sf-junit>
  </target>

  <!-- refactoring of test run process-->
  <target name="init-system-test-run" depends="init-tests,probe-for-components,declare-system-test-tasks">

    <presetdef name="junit-system-test-run" >
     <sf-junit
      fork="true"
      forkmode="once"
      maxmemory="512m"
      errorProperty="system.test.failed"
      failureProperty="system.test.failed"
       >
      <sysproperty key="test.smartfrog.classesdir"
        value="${test.smartfrog.classesdir}" />
       <sysproperty key="test.classes.dir"
           value="${test.classes.dir}"/>
      <syspropertyset >
        <propertyref prefix="runtime"/>
      </syspropertyset>
      <syspropertyset>
        <propertyref prefix="test."/>
      </syspropertyset>
      <classpath refid="testharness.daemon.classpath"/>
      <!-- #Test case isolation technique -->
      <test todir="${test.data.dir}" name="${testcase}" if="testcase"/>
      <batchtest todir="${test.data.dir}" unless="testcase" >
        <!-- bulk test case -->
        <fileset dir="${test.classes.dir}">
          <!-- pull in everything -->
          <include name="org/smartfrog/test/system/**/*Test.class" />

          <!-- failing tests excluded unless run.failing.tests is set -->
          <patternset refid="teststhatfail"/>

          <!-- other conditional components -->
          <exclude name="${componenttests}logger/**/*Test.class"
            unless="logger.present"/>
          <exclude name="${componenttests}utils/**/*Test.class"
            unless="installer.present"/>

        </fileset>
      </batchtest>
     </sf-junit>
    </presetdef>
  </target>

  <!-- ========================================================== -->
  <!-- define the presetdef to run the daemon all set up with the -->
  <!-- right classpath. -->
  <!-- ========================================================== -->
  <target name="init-daemon-with-logging"
      depends="declare-extended-smartfrog-tasks,declare-classpaths,init-tests"
      >
    <property name="config.dir"
        location="${test.classes.dir}/org/smartfrog/test/configuration" />
    <property name="smartfrog.iniFile"
        location="${config.dir}/default.ini" />
    <available file="${smartfrog.iniFile}" property="inifile.found"/>
    <fail unless="inifile.found">No file:${smartfrog.iniFile}</fail>
    <presetdef name="start-logging-daemon">
      <sf-startdaemon-debug failonerror="false"
          spawn="false"
          classpathref="testharness.daemon.classpath">
        <sysproperty key="java.util.config.logging.config.file"
            file="${config.dir}/logging.properties" />
        <sysproperty key="org.smartfrog.iniFile"
            file="${smartfrog.iniFile}" />
        <sysproperty key="org.smartfrog.sfcore.processcompound.sfDefault.sfDefault"
            file="${config.dir}/default.sf" />
      </sf-startdaemon-debug>
    </presetdef>
  </target>


  <!-- ========================================================== -->
  <!-- look for the varous components so that we can make test
  suites conditional on their presence/absence -->
  <!-- ========================================================== -->

  <target name="probe-for-components" depends="init-tests,package-tests">


    <macrodef name="probe4" >
      <attribute name="resource" />
      <attribute name="property" />
      <sequential >
        <available
            property="@{property}" resource="@{resource}"
            classpathref="testharness.daemon.classpath"
            ignoresystemclasses="true"/>
        <echo level="verbose" message="@{resource} availability is ${@{property}}"/>
      </sequential>
    </macrodef>

    <probe4 resource="org/smartfrog/services/installer/sfInstaller.sf"
        property="installer.present"/>
  </target>

  <!-- =================================================================== -->
  <!-- system tests -->
  <!-- we don't force a failure in this target if the tests failed, because-->
  <!-- there is existing code to run reports and halt-->
  <!-- =================================================================== -->
  <target name="system-tests" depends="ready-to-test,init-daemon-with-logging,
    init-system-test-run"
    description="run system tests"
    if="system.tests.enabled">
    <sf-system-test>
      <application>
        <start-logging-daemon />
      </application>
      <test>
        <junit-system-test-run/>
        <sf-system-test-validate/>
      </test>
    </sf-system-test>


  </target>

</project>
