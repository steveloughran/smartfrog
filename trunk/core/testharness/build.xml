<?xml version="1.0"?>
<project name="testharness" default="default">

<!--
/** (C) Copyright 1998-2007 Hewlett-Packard Development Company, LP

This library is free software; you can redistribute it and/or
modify it under the terms of the GNU Lesser General Public
License as published by the Free Software Foundation; either
version 2.1 of the License, or (at your option) any later version.

This library is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public
License along with this library; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

For more information: www.smartfrog.org

*/
-->

<description>
  This is the build file for the test harness for smartfrog.
  It depends on smartfrog being built in the directory tree
  ../smartfrog (override smartfrog.home to change),
  and with ../smartfrog/dist/lib/smartfrog.jar existing.
  It also needs junit3.8.1 or 3.8.2 or later in ANT_HOME/lib,
  and a recent copy of Xalan to turn the XML Reports into HTML.
  These reports are all placed in build/test/reports, incidentally.

  To run just one test, run the test target with the testcase property set to
  the full name of the test, e.g.
    -Dtestcase=org.smartfrog.test.unit.core.coreTest

  You can enable/disable unit tests by setting unit.tests to true or false;
  system tests by setting system.tests to true or false. By default both are enabled.

  Do not run the system tests outside a secure environment, unless
  you are running a daemon that is secure.

  The target "dist" creates a jar file in the dist/lib directory,
  that contains all the utility classes needed to deploy smartfrog
  programs as part of a unit test system. It is designed to be reusable
  when testing other components. The "published" target publishes this
  to the ivy repository


</description>

   <!-- override point -->
  <property file="build.properties" />
  <property name="ivy.enabled" value="true"/>
  <!-- this component keeps its test files in a different place from the
       rest, for historical reasons (i.e. it is nothing but test) -->
  <property name="test.src.dir" location="testcases" />

  <property name="root.dir" location=".."  />

  <!-- Import common stuff -->
  <import file="${root.dir}/common.xml"/>


  <!--the default target publishes then runs the test. Why so?
    so that even if the tests fail, downstream things can use the testharness-->
  <target name="default" depends="published,test" />

  <!-- ========================================================== -->
  <!-- Test settings                                              -->
  <!-- ========================================================== -->

  <target name="init" depends="common.init,use-smartfrog-tasks">

    <property name="test.smartfrog.classesdir" location="${test.classes.dir}"/>
    
    <!-- load in our runtime properties too, so we can use presence/absence of
         values as a cue -->
    <property file="${runtime.properties}" prefix="runtime" />
    <property name="services" value="org/smartfrog/services/" />
    <property name="unittests" value="org/smartfrog/test/unit/" />
    <property name="systemtests" value="org/smartfrog/test/system/" />
    <property name="processtests" value="org/smartfrog/test/process/"/>
    <property name="componenttests" value="${systemtests}components/" />
  </target>


  <!-- ========================================================== -->
  <!-- this is the gump entry point; it does packaging but not the tests -->
  <!-- ========================================================== -->
  <target name="gump"
          depends="dist,published"
          description="target for gump builds"
    />

  <!-- replace the normal test with a simple noop, because we will
      not have the test harness around in the early stages of the build -->
  <target name="assert-smartfrog-testharness" />

  <target name="package-tests" depends="rmi-tests,common.package-tests"
    description="create the JAR file for the tests"/>

  <!-- ========================================================== -->
  <!-- compile the RMI. This is separate from the other compile, so that unit
       tests dont depend on it -->
  <!-- ========================================================== -->
  <target name="rmi-tests"
    depends="compile-tests">
    <sf-rmic includesfile="rmitargets" 
      base="${test.classes.dir}"
      verify="true">
      <classpath refid="tests.compile.classpath"/>
    </sf-rmic>
  </target>

  <!-- ========================================================== -->
  <!-- conditionally start the daemon if one was not found already-->
  <!-- and do not complain if it could not start (or execution timed out) -->
  <!-- ========================================================== -->
  <target name="start-daemon-if-needed-with-logging"
    depends="use-smartfrog-tasks,probe-local-daemon,init-daemon-with-logging"
    unless="local.daemon.running">
    <start-logging-daemon/>
  </target>


  <!-- ========================================================== -->
  <!-- define the presetdef to run the daemon all set up with the -->
  <!-- right classpath. -->
  <!-- ========================================================== -->
  <target name="init-daemon-with-logging"
    depends="declare-extended-smartfrog-tasks,declare-classpaths"
    >
    <property name="config.dir"
      location="${test.classes.dir}/org/smartfrog/test/configuration" />
    <property name="smartfrog.iniFile"
      location="${config.dir}/default.ini" />
    <available file="${smartfrog.iniFile}" property="inifile.found"/>
    <fail unless="inifile.found">No file:${smartfrog.iniFile}</fail>
    <presetdef name="start-logging-daemon">
      <sf-startdaemon-debug  failonerror="false"
          classpathref="tests.run.classpath">
        <sysproperty key="java.util.config.logging.config.file"
          file="${config.dir}/logging.properties" />
        <sysproperty key="org.smartfrog.iniFile"
          file="${smartfrog.iniFile}" />
        <sysproperty key="org.smartfrog.sfcore.processcompound.sfDefault.sfDefault"
          file="${config.dir}/default.sf" />
      </sf-startdaemon-debug>
    </presetdef>
  </target>


    <!-- ========================================================== -->
  <!-- look for the varous components so that we can make test 
  suites conditional on their presence/absence -->
  <!-- ========================================================== -->
  
  <target name="probe-for-components" depends="init">
    <presetdef name="probe4" > 
      <available classpathref="tests.run.classpath" ignoresystemclasses="true"/>
    </presetdef>

    <probe4 resource="org/smartfrog/services/ant/components.sf" property="ant.present"/>
    <probe4 resource="org/smartfrog/services/email/emailer.sf" property="emailer.present"/>
    <probe4 resource="org/smartfrog/services/scripting/scriptPrim.sf"
      property="scripting.present"/>    
    <probe4 resource="org/smartfrog/services/ssh/password.sf"
      property="ssh.present"/>    
    <probe4 resource="org/smartfrog/services/comm/slp/sf/SFSlpDA.sf"
      property="slp.present"/> 
    <probe4 resource="org/smartfrog/services/installer/sfInstaller.sf"
      property="utils.present"/> 
  </target>

      
  <target name="init-tests" depends="package-tests">
    <!--A list of all tests that fail-->
    <!-- if you add a test here, file a bugrep against it in jira
      and refer to it in this list. That way we can track which tests
       fail and why
    -->
    <patternset id="teststhatfail">
      <exclude unless="run.failing.tests" name="${systemtests}/java/LibraryTest.*"/>
      <!--http://jira.smartfrog.org/jira/browse/SFOS-25-->
      <exclude name="${systemtests}/workflow/sequence/SequenceTest.*"
          unless="run.failing.tests" />
      <!-- 2006-10-18: steve_l commented out while still finishing off the component,
        so Cruise Control doesn't fail-->
      <exclude name="${systemtests}/assertions/testcompounds/TestCompoundsTest.*"
          unless="run.failing.tests" />
    </patternset>
  </target>
  
  <!-- ========================================================== -->
  <!-- run the unit tests -->
  <!-- ========================================================== -->
  <target name="unit-tests" depends="init-tests"  unless="testcase"
    description="run unit tests">
    <sf-junit
           errorProperty="test.failed"
           failureProperty="test.failed"
           >
      <sysproperty key="test.smartfrog.classesdir"
          value="${test.smartfrog.classesdir}" />
      <syspropertyset >
        <propertyref prefix="runtime"/>
      </syspropertyset>       
      <syspropertyset >
        <propertyref prefix="smartfrog"/>
      </syspropertyset>  
      <classpath>
        <path refid="tests.run.classpath"/>
      </classpath>
      <batchtest todir="${test.data.dir}" if="unit.tests.enabled">
        <!-- bulk test case -->
        <fileset dir="${test.classes.dir}">
          <include name="${unittests}**/*Test.class" />
       </fileset>
      </batchtest>
    </sf-junit>
  </target>
  

  <!-- refactoring of test run process-->
  <target name="init-system-test-run" depends="init-tests,probe-for-components">
    <presetdef name="junit-system-test-run" >
    <sf-junit
      errorProperty="test.failed"
      failureProperty="test.failed"
      >
      <sysproperty key="test.smartfrog.classesdir"
        value="${test.smartfrog.classesdir}" />
      <syspropertyset >
        <propertyref prefix="runtime"/>
      </syspropertyset>
      <classpath>
        <path refid="tests.run.classpath"/>
      </classpath>
      <!-- #Test case isolation technique -->
      <test todir="${test.data.dir}" name="${testcase}" if="testcase"/>
      <batchtest todir="${test.data.dir}" unless="testcase" >
        <!-- bulk test case -->
        <fileset dir="${test.classes.dir}">
          <!-- pull in everything -->
          <include name="org/smartfrog/test/system/**/*Test.class" />

          <!-- failing tests excluded unless run.failing.tests is set -->
          <patternset refid="teststhatfail"/>

          <!-- other conditional components -->
          <exclude name="${componenttests}ssh/**/*Test.class"
            unless="ssh.present"/>
          <exclude name="${componenttests}scripting/**/*Test.class"
            unless="scripting.present"/>
          <exclude name="${componenttests}net/**/*Test.class"
            unless="net.present"/>
          <exclude name="${componenttests}logger/**/*Test.class"
            unless="logger.present"/>
          <exclude name="${componenttests}emailer/**/*Test.class"
            unless="emailer.present"/>
          <exclude name="${componenttests}ant/**/*Test.class"
            unless="ant.present"/>
          <exclude name="${componenttests}slp/**/*Test.class"
            unless="slp.present"/>
          <exclude name="${componenttests}utils/**/*Test.class"
            unless="utils.present"/>

        </fileset>
      </batchtest>
    </sf-junit>
    </presetdef>
  </target>

  <!-- =================================================================== -->
  <!-- system tests -->
  <!-- we don't force a failure in this target if the tests failed, because-->
  <!-- there is existing code to run reports and halt-->
  <!-- =================================================================== -->
  <target name="system-tests" depends="common.system-tests,init-daemon-with-logging,
    init-system-test-run"
    description="run system tests"
    if="system.tests.enabled">
    <sf-functionaltest testTimeout="600" shutdownTime="60">
      <application>
        <!-- if the port is in use, this will fail to open the port-->
        <!-- which is ok as we want to debug. but, the running daemon will-->
        <!-- always be stopped afterwards-->
        <start-logging-daemon spawn="false"/>
      </application>
      <probe>
        <socket port="${smartfrog.daemon.port}" server="localhost"/>
      </probe>
      <test>
        <junit-system-test-run/>
        <!--<fail if="test.failed">Junit failed</fail>-->
      </test>
      <teardown>
        <sf-stopdaemon failonerror="false"/>
<!--
        <sf-junitreport data="${test.data.dir}"
          reports="${test.reports.dir}"
          />
-->
      </teardown>
    </sf-functionaltest>
  </target>

</project>
