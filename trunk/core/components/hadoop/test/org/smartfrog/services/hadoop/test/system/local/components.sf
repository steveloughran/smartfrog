/* (C) Copyright 2008 Hewlett-Packard Development Company, LP

 This library is free software; you can redistribute it and/or
 modify it under the terms of the GNU Lesser General Public
 License as published by the Free Software Foundation; either
 version 2.1 of the License, or (at your option) any later version.

 This library is distributed in the hope that it will be useful,
 but WITHOUT ANY WARRANTY; without even the implied warranty of
 MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 Lesser General Public License for more details.

 You should have received a copy of the GNU Lesser General Public
 License along with this library; if not, write to the Free Software
 Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

 For more information: www.smartfrog.org

 */


#include "/org/smartfrog/services/hadoop/test/system/components.sf"


LocalDataNodeCompound extends TransientNameDataNodeCompound;


OrphanDatanodeCompound  extends LocalHadoopCompound  {

  description "A cluster with a task tracker but not job tracker";

  localDataDir extends TempDir {

  }

  datanode extends  LightweightDataNode {
    fs.default.name PARENT:fs.default.name;
    dataDirectories [LAZY localDataDir];
    logDir LAZY PARENT:logDir;
    dfs.datanode.address dataNodeURL  ;
  }
}



TwoDataNodeCluster extends LocalDataNodeCompound {
  localDataDir2 extends TempDir {

  }

  datanode2 extends datanode {
    dataDirectories [LAZY localDataDir2];
    dfs.datanode.https.address any_port;
  }
}

/**
 * A complete filesystem
 */
LocalFileSystemCompound extends FilesystemWithActions {


}


LocalJobTrackerCompound2 extends LocalFileSystemCompound {
  description "A cluster with a job tracker";

  jobTracker extends LightweightJobTracker {
    fs.default.name PARENT:ATTRIB fs.default.name;
    dataDir LAZY PARENT:ATTRIB dataDir;
    dataDirectories [dataDir];
    nameDir LAZY PARENT:ATTRIB nameDir;
    nameDirectories [nameDir];
    logDir LAZY PARENT:ATTRIB logDir;
  }
}

OrphanTaskTrackerCompound extends LocalHadoopCompound  {

  description "A cluster with a task tracker but not job tracker";

  mapred.job.tracker HadoopConfiguration:mapred.job.tracker;

  taskTracker extends LightweightTaskTracker {
    fs.default.name PARENT:ATTRIB fs.default.name;
    mapred.job.tracker LAZY PARENT:ATTRIB mapred.job.tracker;
    //yes, this is milliseconds. But there is a sleep involved too
    mapred.task.tracker.connect.timeout ORPHAN_CONNECT_TIMEOUT;

    //"ipc.client.connect.max.retries"
    ipc.client.connect.max.retries ORPHAN_CONNECT_MAX_RETRIES;
    
  }
}




/**
Test sequence that checks that when a namenode is shut down, it goes away
*/
NamenodeShutdownSequence extends Sequence {
  namenode TBD;

  waitForNameNode extends WaitForServiceLive {
    serviceName "namenode";
    service LAZY PARENT:namenode;
  }


  //detach and terminate
  terminateNameNode extends Terminator {
    kill LAZY PARENT:namenode;
    detachFirst true;
  }

  //now assert that it is dead
  assertIPCClosed extends AssertNameNodeIPCClosed;
  assertHttpClosed extends AssertNameNodeHttpClosed;
}

FileSystemLiveSequence extends Sequence {

    namenode TBD;
    datanode TBD;
    datanodeCount 1;
    //the cluster for all the tests
    cluster namenode;

    waitForNameNode extends WaitForNameNodeLive {
      service LAZY PARENT:namenode;
    }

    waitForDataNode extends WaitForDataNodeLive {
      service LAZY PARENT:datanode;
    }


}


/**
 * A sequence of operations on a cluster */
FileSystemTestSequence extends FileSystemLiveSequence {



    rootDirExists extends DfsPathExistsWorkflow {
      cluster LAZY PARENT:cluster;
      path "/";
    }

    touch extends DfsCreateFile {
      cluster LAZY PARENT:cluster;
      path "/test-filename";
      text "this is a very small file for Hadoop";
    }

    assertFileExists extends DfsPathExistsWorkflow {
      cluster LAZY PARENT:cluster;
      path touch:path;
    }

  }

  FileCreation extends Compound  {
    cluster TBD;
    dest TBD;

    sfShouldTerminate true;

    sourceFile extends InlineTupleSource {
      data [
        ["one",43],
        ["two", "43"],
        ["one",12]
      ]

    }

    UploadHadoopCsvFile extends TuplesToHadoop {
      cluster LAZY PARENT:cluster;
      source LAZY sourceFile;
      dest testFile;

    }
  }

TestJob extends Job {
  name TBD;
  cluster TBD;
  jobTracker TBD;
  fs.default.name cluster:fs.default.name;
  mapred.job.tracker jobTracker:mapred.job.tracker;
  hadoop.tmp.dir "/tmp";

  //mapred.system.dir "/tmp/hadoop/mapred/system";

  mapred.child.java.opts "-Xmx512m -d64 -server";
  mapred.tasktracker.map.tasks.maximum 5;
  mapred.tasktracker.reduce.tasks.maximum 1;
  mapred.working.dir (hadoop.tmp.dir ++ "/" ++ name ++ "/working");
  mapred.local.dir (hadoop.tmp.dir ++ "/" ++ name ++ "local");
  //hadoop.job.ugi ;
}

TestJobNoFile extends TestJob {
  mapred.input.dir testDirIn;
  mapred.output.dir testDirOut;
}

Sleep extends Delay {
  time STARTUP_SLEEP_TIME;
}

LocalClusterStatus extends ClusterStatus {
  jobTracker TBD;

  fs.default.name jobTracker:fs.default.name;
  mapred.job.tracker jobTracker;
  hadoop.job.ugi jobTracker:hadoop.job.ugi;
  sfShouldTerminate true;
  supportedFileSystem true;
}


/**
 * sequence that waits for the filesystem and job trackers
 */

JobTrackerSequence extends FileSystemLiveSequence {

  jobTracker TBD;
  taskTracker TBD;

  sleep extends Sleep;

  waitForTaskTracker extends WaitForServiceLive {
    serviceName "TaskTracker";
    service LAZY PARENT:taskTracker;
  }

  waitForJobTracker extends WaitForJobTrackerLive {
    service LAZY PARENT:jobTracker;
  }

/*  waitForFilesystem extends WaitForFilesystemLive {
    service LAZY PARENT:jobTracker;
    minCount datanodeCount;
  }*/

}

/**
 * this is a complete MR workflow
 */
MapReduceTestSequence extends JobTrackerSequence {

  testDir "/tests/mrtestsequence";
  testDirIn  (testDir ++ "/in");
  testDirOut (testDir ++ "/out");
  testDirWorking (testDir ++ "/working");
  testFile (testDirIn ++ "/in.txt");
  inputFileDFS testFile;
  outputFileDFS ( testDirOut ++ "/in.txt");
  LocalDataDir PROPERTY test.work.dir;
  inputFileLocal (LocalDataDir  ++ "/in.txt")
  outputFileLocal (LocalDataDir  ++ "/out.txt")

  inputFile extends TextFile {
    filename inputFileLocal;
    createParentDirs true;
    sfShouldTerminate true;
    text ##1,one,un,ein
2,two,deux,zwei
3,three,trois,drei
4,four,quatre,vier
5,five,cinq,funf#;
  }

     
  CopyDataIn extends DfsCopyFileIn {
    cluster LAZY PARENT:cluster;
    source inputFileLocal;
    dest testFile;
    sfShouldTerminate true;
  }

  SourceExists extends DfsPathExistsWorkflow {
    cluster LAZY PARENT:cluster;
    path inputFileDFS;
  }

  lsIn extends DfsListDir {
    cluster LAZY PARENT:cluster;
    path  testDirIn;
  }

  mkOutputDir extends DfsCreateDir {
    cluster LAZY PARENT:cluster;
    path  testDirOut;
 }


  MRCompound extends Parallel {
    job extends TestJob  {
          //this is the job information
      jobTracker LAZY PARENT:PARENT:jobTracker;
      cluster LAZY PARENT:PARENT:cluster;
      name "testsubmission";
      mapred.input.dir testDirIn;
      mapred.output.dir testDirOut;
      mapred.working.dir testDirWorking;
      mapred.local.dir (testDir ++ "/local");
      mapred.mapper.new-api true;
      //mapred.job.split.file (testDir ++ "/split");
      mapred.job.tracker jobTracker:mapred.job.tracker;
      keep.failed.task.files true;
      filename "";


      fs.default.name cluster:fs.default.name;
    }

    submission extends BlockingJobSubmitter {
      //get our settings from ourselves.
      job LAZY PARENT:job;
      mapred.mapper.new-api true;
      cluster LAZY PARENT:PARENT:cluster;
      fileRequired false;
    }

  }

  s1 extends Sleep;

  lsOut extends DfsListDir {
    cluster LAZY PARENT:cluster;
    path  testDirOut;
  }

  ResultExists extends DfsPathExistsWorkflow {
    cluster LAZY PARENT:cluster;
    path outputFileDFS;
  }

  CopyDataOut extends DfsCopyFileOut {
    cluster LAZY PARENT:cluster;
    source outputFileDFS;
    dest outputFileLocal;
    sfShouldTerminate true;
  }

}



