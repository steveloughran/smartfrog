\section{The Fundamental Flaws of JAX-RPC}
\label{objections}

\subsection{The Object/XML Impedance Mismatch}
\label{objections:o-x}

JAX-RPC attempts to turn an XML document into Java classes derived from the type
information attached to nodes. This is distinct from the type of mapping
performed by DOM implementations, in that the classes are ``serialised'' from
the XML tree, not merely created to represent it (it is a semantic rather than
syntactic mapping). This serialisation/deserialisation is an essential part of
JAX-RPC, allowing method calls to be translated into SOAP requests, and
responses translated back into Java objects.

We believe that the term \emph{serialisation} downplays the nature of
the problem, likening it to the more tractable problem of creating a
non-portable persistence format for a class. 

We prefer to use the term \emph{O/X mapping} to emphasise the
similarities it has with the heavily studied \emph{O/R mapping
problem}\footnote{ \emph{"Object-relational mapping is the Vietnam of
Computer Science"} - Ted Neward. He means that it's a problem you can
never declare victory over, merely invest more and more effort in to
get deeper into the quagmire.
%{\small \tt http://www.neward.net/ted/weblog/index.jsp?date=20041003#1096871640048}
}. 
Over a decade has been spent trying to map between records in relational
databases and language-level objects, and there is still no sign of an ideal
solution. There is significantly less experience in mapping between XML and
objects, and rather than drawing on the experiences of the many failed attempts
at O/R mapping, O/X mapping technologies appear destined to share a similar
evolution.

At first glance, O/X mapping appears simple: create a Java object
for each XML element, building a DAG\footnote{directed, acyclic graph}
when serialising to rpc/encoded SOAP or a tree with doc/lit
messages. Read or write between attributes and class fields, bind to
children and the conversion is complete. If only it were so
straightforward. There is a fundamental difference between the type
systems of XML --especially that of XML Schema-- and that of Java.


\subsubsection{Binding XML Elements to Java Classes}
\label{objections:o-x:xml-classes}

The language of XMLSchema is much richer than the object model of
Java. In Java, inheritance can extend a type, and change some existing
semantics, but derivation by restriction is not explictly
supported. Java, in common with many object oriented programming
environments, allows derived types to expand upon the capabilities of
their parents, but not to decrease them. That is, one can add attributes and
methods, but not remove them. XML schema lets one extend a type by 
restricting it, constraining attribute and element values.

This fundamental difference means that one cannot accurately model an
XSD type hierarchy in a Java class hierarchy. All one can do is inaccurately
model it. 

Here, for example, a postcode is modelled by restricting a string

%\todo{more entertaining example. something like `us-beer' is a 
%restriction of type `beer' where alcohol is a removed attribute}


\begin{verbatim}
<simpleType name="UKPostcode">
 <restriction base="xsd:string">
  <pattern value="[A-Z]{2}\d \d[A-Z]{2}"/>
 </restriction>
</simpleType>
\end{verbatim}

The actual result is going to be a simple class of type string; all restriction information
will be lost in the transformation from WSDL to Java. 

This is a fundamental difference, and one which would appear to remain
intractible except in special cases addressed on a case-by-case
basis.

\subsubsection{Mapping XML Names to Java Identifiers}
\label{objections:o-x:names}


Not all XML names can be turned into Java identifiers. 
XML names must begin with a letter in one of many Unicode languages,
an ideograph or a an underscore (``\_'') . They can be followed by any of the same
characters, and also a hyphen ``-'' or a full stop ``.''. Some examples
are: {\tt schr\"odinger}, {\tt \_unknown.type-set}, and {\tt String}.

Java identifiers are almost a proper subset of XML names
\footnote{Java names are not a subset only because XML names beginning in "xml" (any case) are reserved},
which means that the system needs to map from the XML names to valid
class and package names, package names being derived from namespace URLs
if not overridden. This naming is inordinately complex. When a new version
of Java is released, the mapping logic needs to be updated to add new
reserved works (such as {\tt assert} and {\tt enum}), else the
generated code will no longer compile in the enhanced language. Such an
upgrade will break any existing code that linked to classes using these
names. 


\subsubsection{Enumerations}

One specific example that deserves special mention is how
{\tt xsd:enumeration} declarations are mapped to Java. Prior to
Java1.5, there was no explict {\tt enum} clause in the language, so
workarounds were developed. The JAX-RPC solution is that of a common
pattern: to declare a class with a public static instance representing
a valid enumeration value. The WSDL to Java code generates such a
class, with the name of each static class taken from the name of each
value in the enumeration. 

This is a simple example of how O/X mapping should work. Except, what if the
value of the one of the enumeration types is a reserved word?
Take the lifecycle state machine we have:

\begin{verbatim}
<xsd:simpleType name="lifecycleStateEnum">
  <xsd:restriction base="xsd:string"> 
    <xsd:enumeration value="initialized"/> 
    <xsd:enumeration value="running"/> 
    <xsd:enumeration value="failed"/> 
    <xsd:enumeration value="terminated"/> 
    <xsd:enumeration value="null"/> 
  </xsd:restriction>
</xsd:simpleType>
\end{verbatim}

One element in the enumeration is reserved, {\tt null}. The JAX-RPC
specification states that the implementation must must now enumerate all
states as {\tt value1}, {\tt value2}, and so on, for the entire list.
This means the enumeration names in the Java source no longer contains
any value at all, other than the position number in the set. This is
inordinately brittle, as any change to the enumeration could reorder the
values, without the code detecting a change.


\subsubsection{Unportable types}
\label{objections:o-x:types}

Some Java types are explicitly unportable. One would not expect to be
able to have a SOAP runtime serialise a database connection instance and
have it read at the far end. One would hope that a hashtable could be
translated to a structure that would be turned into a platform-specific
equivalent at the far end. Yet surely, surely, a {\tt java.util.Calendar}
object could be sent over the wire, as it maps so well to the
{\tt xsd:dateTime} type in XML schema.

Certainly we can send such times. They are readable on the wire, and
they get mapped into whatever a platform has at the far end to represent
time. Unfortunately, due to differences in expectations between Java and
.NET date/time classes, we can not guarantee that the same time will be
received at the far end. If both client and server are in the UTC time
zone all works well, but if either of them are in a different location,
hours appear to get added or removed. Clearly a different expectation
regarding time processing is taking place. 

This is an insidious class of defect as it is not apparent on any
testing which takes place in the same time zone, or between Java
implementations. It is only apparent when remote callers, using
different platforms, attempt to use the service.

Our service API now uses UTC seconds since 1/1/1970, the classic {\tt time\_t}
format, as our time representation. This is no longer human readable,
but it works. 

\subsubsection{Message validation}
\label{objections:o-x:validation}


When a message is received, the serialised form is generated and passed
to the handlers for processing. What does not take place is any
validation of the incoming XML against the schema. In particular, any
restrictions on the number of times an item is required are not checked.

This forces the implementation code to follow one of two paths.
Firstly, it could ignore the problem. If the client code and functional
tests do not generate invalid messages --as is likely if they are also
all written in JAX-RPC-- then the problem not be noticed. It will only
surface when a third party attempts to use the service.
Secondly, the developers could write the procedural logic to verify that
the java classes representing the deserialised message have a structure
that matches the expectations of the schema. This requires an
understanding of the schema, knowledge of the serialisation mapping and
potential troublespots,  the willingness to write the tests to validate
this extra logic, and most of all, time. 

We suspect that most services err on the side of ignorance, and do not
validate their incoming messages adequately.


\subsubsection{Inadequate Mixing of XML and Serialised Data}
\label{objections:o-x:mixing}

JAX-RPC and JAXM are two different views of the world. What does JAX-RPC
do when it encounters a piece of random XML in a message? It creates a
JAXM {\tt Node} to describe that part of the tree.

From then on, the tree below that node is permanently isolated from the
JAX-RPC; the developer has sailed off the edge of the JAX-RPC world, and
fallen into the universe of XML. Any O/X mappings which may exist for data
within this piece of the message are now inaccessible, all that is left
is the low-level JAX-M API. It is as if incorporating arbitrary XML
within a SOAP message is not an approved action, yet this is the key
aspect of SOAP's flexibility; a key to its aim of being more extensible
and less brittle than its predecessors.


\subsubsection{Fault processing}
\label{objections:soap-not-rmi:faults}

JAX-RPC tries to marshall Java faults over the network, in such a way
that they can be reconstituted at the far end into the same fault. To
manage this is a somewhat complex process, as the class name of the
fault must be exchanged as the fault code. As faults are often
immutable, the standard serialisation mechanism of named getter and
setter methods is replaced by one more exotic. Getter methods are used
to extract the contents of a fault, a fault which must offer a
constructor that takes every attribute in a parameter of the same name
\footnote{this implicitly requires code to be built with debugging
information.}.

We believe attempting to seamlessly marshall faults is a mistaken
approach.  By propagating the still controversial ``declare all
possible faults'' rule of Java into remote interfaces, it exposes
platform implementation details. If a service could only raise a
normal {\tt SOAPFault} unless its developers explicitly declared and
implemented custom WSDL fault elements, service definition would be
platform-neutral.

%% I don't understand the relevance of this so I cut it
% As well as the marshalled faults, the specification includes one
% standard fault, {\tt SoapFaultException}.

Exposing implementation details in the service interface makes ensuring
interoperability much more difficult. We recall that interoperability
was yet another reason for adopting SOAP initially, and that this is yet
another capability of SOAP's which JAX-RPC fails to deliver upon.

\subsection{SOAP is not just RPC}
\label{objections:soap-not-just-rmi}

SOAP's parentage includes XML-RPC \cite{winer:xmlrpc} and indirectly
COM/DCOM \cite{dbox:com};
was clearly designed at its outset to be a form of remote procedure call
in XML, over HTTP.

Over time that world-view has changed. While it is often presented as
a form of RPC, it can also be viewed as a system where arbitrary XML documents
are exchanged between parties, potentially asynchronously, and potentially
via intermediares. 

In this world, a programming paradigm that seemed appropriate for an RPC
infrastructure, looks out of place.


On a fast network, RPC invocation is often a good choice as a
communication paradigm. Other models of communication are harder to
code, and the benefits are not apparent. When working over long-haul
connections, however, or with large content (eg fifteen megabyte
attachments), the limitations of RPC become clear. 

Currently, our only option is to split network communication into a
separate thread from the rest of the program. While this works, it
provides the programmer no way to give the user effective feedback or
control over the communications. There is no way to receive progress
notifications or cancel an active call, even though the underlying
transport code invariably permits such features.

Again, following our principle that SOAP technologies should
attempt to work to the same goals as SOAP itself, we note that SOAP
was designed to work over long haul connections (and be simple). By
making it both difficult and complicated to work over a long
connection, JAX-RPC fails to meet these criteria for a SOAP
technology.

\subsection{SOAP is not RMI}
\label{objections:soap-not-rmi}

JAX-RPC suffers from a greater flaw than those classically associated
with RPC invocation: it tries to make the communications look like
Java RMI. Java RMI is a simple and effective mechanism for connecting
Java classes running on different machines. It is an IDL-free
communication mechanism, which relies on introspection to create proxy
classes and to marshall classes. It works because the systems at both
ends are Java, usually different pieces of a single larger
application. Even then, it works best if both ends are running the same
version of all classes.

With synchronised versions of common code, objects can be trivially
serialised and sent over a network connection. Exceptions are just
another type of object, and so too can be sent over the wire. There is
no need for an IDL, as Java interface declarations can perform much of
the same role. And as the recipient is a remote object, state is
automatic.  One can even keep code synchronized by using a special
classloader, one that fetches code from jointly-accessible URLs.

JAX-RPC tries to reuse many of the programming patterns of RMI. For
example, the runtime will attempt to serialise classes marked as
{\tt Serialisable}, ignoring those fields marked as
{\tt transient}. It will even serialise complex compound objects where
possible. The user appears to have a reference to something like an
object, though one that represents the current conversation with an
endpoint, not a direct endpoint proxy.

% When a message gets delivered to its endpoint, the normal handler for
% dispatching the message creates an instance of the relevant Java class
% and then dispatches the request to it. The message is turned into an
% invocation of an instance of a remote object, which certainly looks
% like RMI, even if the lifecycle of the class is radically different.

SOAP strove to overcome many of the failings of precursor technologies
like CORBA and DCOM. These technologies work well over local area
networks, and enable rich bidirectional communications, but are not
completely cross platform\footnote{Arguably for political rather than
technical reasons}, and ended up being used to produce distributed
object systems that were too tightly coupled. Recall that one of our
key hopes from adopting SOAP (section \ref{introduction}) was to
enable loose coupling between components of a distributed system.

While Java RMI provides convenience, the preceding paragraphs
should have made clear that one thing it does not provide in any way
is loose coupling. Interacting systems typically run from the same
codebase (indeed running them from different codebases can pose
significant problems). By trying to turn SOAP into RMI, we risk losing
the very things we turned to SOAP for in the first place.

% Tight coupling has proven to be a bad thing in a distributed
% system. If components are too tightly coupled, it implies that the
% separate components have merged to become one large system, one which
% cannot be treated except as a whole. And in a sufficiently large
% system, it is impossible to co-ordinate the whole \cite{deutsch,
% jini}. The move towards SOAP and a service oriented architecture was
% advocated as a means of dealing with loose organisational coupling, by
% forcing a loose data coupling between applications.



\input{wsdl}


