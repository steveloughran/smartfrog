/* (C) Copyright 2009 Hewlett-Packard Development Company, LP

This library is free software; you can redistribute it and/or
modify it under the terms of the GNU Lesser General Public
License as published by the Free Software Foundation; either
version 2.1 of the License, or (at your option) any later version.

This library is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public
License along with this library; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

For more information: www.smartfrog.org

*/

#include "/org/smartfrog/extras/hadoop/cluster/bindings.sf"

ClusterNameNodeCompound extends TransientNameNodeCompound {

  namenodeHost extends Localhost;

  threads WORKER_THREADS;
  //localhost.name APPLY lookupLocalhost;
  namenodeHostname LAZY namenodeHost:hostname;
  hostname namenodeHostname;
  fs.default.name ("hdfs://" ++ (namenodeHostname) ++ ":" ++ NameNodeIpcPort ++ "/");
// WAS  namenode.filesystem;
  namenode:dfs.datanode.handler.count threads;
  namenode:checkRunning false;
}

ClusterDataNodeCompound extends TransientDataNodeCompound {
  threads WORKER_THREADS;
  fs.default.name  TBD;
  workerHost extends Localhost;
  hostname "0.0.0.0";
//  fs.default.name namenode.filesystem;
  //datanode:mapred.job.tracker.handler.count threads;
}

ClusterJobTrackerCompound extends TransientJobTrackerCompound  {
  threads WORKER_THREADS;
  fs.default.name  TBD;

  jobtrackerHost extends Localhost;

//  fs.default.name namenode.filesystem;
  jobtracker:mapred.job.tracker.handler.count threads;
}


ClusterTaskTrackerCompound extends TransientTaskTrackerCompound  {
  threads WORKER_THREADS;
//  fs.default.name namenode.filesystem;
  tasktracker.http.threads threads;
  workerHost extends Localhost;
}


/**
 * The parallel container is used here to leave up any part of the system
 * which can come up. This allows us to permit partial cluster failure, without
 * failing ourselves.
 */
HadoopClusterCompound extends Compound {


}

HadoopFilesystemSingleProcess extends HadoopClusterCompound {

//fs.name LAZY namenode:namenode:live.fs.default.name;
  fs.name LAZY namenode:namenode:fs.default.name;

  namenode extends ClusterNameNodeCompound {
  }

  datanode extends ClusterDataNodeCompound {
    fs.default.name fs.name;
  }


}

HadoopFilesystemMultiProcess extends HadoopFilesystemSingleProcess {

  namenode:sfProcessName NAMENODE_PROCESS;
  datanode:sfProcessName DATANODE1_PROCESS;

}

HadoopFilesystem extends HadoopFilesystemSingleProcess {

}



HadoopClusterSingleProcess extends HadoopFilesystemSingleProcess {


  jobtracker extends ClusterJobTrackerCompound {
    fs.default.name fs.name;
  }


  tasktracker extends ClusterTaskTrackerCompound {
    fs.default.name fs.name;
  }

}

HadoopClusterMultiProcess extends HadoopClusterSingleProcess {
  namenode:sfProcessName NAMENODE_PROCESS;
  datanode:sfProcessName DATANODE1_PROCESS;
  jobtracker:fProcessName JOBTRACKER_PROCESS;
  tasktracker:sfProcessName TASKTRACKER1_PROCESS;
}

HadoopCluster extends HadoopClusterSingleProcess;

ForkedCluster extends HadoopClusterMultiProcess;

DistributedFilesystem extends HadoopFilesystem {
  namenode:sfProcessHost namenode.host;
  datanode:sfProcessHost datanode1.host;
}

DistributedCluster extends HadoopCluster {
  namenode:sfProcessHost namenode.host;
  datanode:sfProcessHost datanode1.host;
  jobtracker:sfProcessHost jobtracker.host;
  tasktracker:sfProcessHost tasktracker1.host;
}

