/* (C) Copyright 2008 Hewlett-Packard Development Company, LP

 This library is free software; you can redistribute it and/or
 modify it under the terms of the GNU Lesser General Public
 License as published by the Free Software Foundation; either
 version 2.1 of the License, or (at your option) any later version.

 This library is distributed in the hope that it will be useful,
 but WITHOUT ANY WARRANTY; without even the implied warranty of
 MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 Lesser General Public License for more details.

 You should have received a copy of the GNU Lesser General Public
 License along with this library; if not, write to the Free Software
 Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

 For more information: www.smartfrog.org

 */


#include "/org/smartfrog/services/hadoop/test/system/components.sf"


//how long a job should take before we give up on it
JOB_TIMEOUT 90000;

LocalDataNodeCompound extends TransientNameDataNodeCompound;


OrphanDatanodeCompound  extends LocalHadoopCompound  {

  description "A cluster with a task tracker but not job tracker";

  localDataDir extends TempDir {

  }

  datanode extends  LightweightDataNode {
    fs.default.name PARENT:fs.default.name;
    dataDirectories [LAZY localDataDir];
    logDir LAZY PARENT:logDir;
    dfs.datanode.address dataNodeURL  ;
  }
}



TwoDataNodeCluster extends LocalDataNodeCompound {
  localDataDir2 extends TempDir {

  }

  datanode2 extends datanode {
    dataDirectories [LAZY localDataDir2];
    dfs.datanode.http.address  (hostaddress ++ ":" ++ DataNodeHttpPort2);
    dfs.datanode.https.address (hostaddress ++ ":" ++ DataNodeHttpsPort2);
    dfs.datanode.address (hostaddress ++ ":" ++ DataNodeIpcPort2)
  }
}

/**
 * A complete filesystem
 */
LocalFileSystemCompound extends FilesystemWithActions {


}


LocalJobTrackerCompound2 extends LocalFileSystemCompound {
  description "A cluster with a job tracker";

  jobTracker extends LightweightJobTracker {
    fs.default.name PARENT:ATTRIB fs.default.name;
    dataDir LAZY PARENT:ATTRIB dataDir;
    dataDirectories [dataDir];
    nameDir LAZY PARENT:ATTRIB nameDir;
    nameDirectories [nameDir];
    logDir LAZY PARENT:ATTRIB logDir;
  }
}

OrphanTaskTrackerCompound extends LocalHadoopCompound  {

  description "A cluster with a task tracker but not job tracker";

  mapred.job.tracker HadoopConfiguration:mapred.job.tracker;

  taskTracker extends LightweightTaskTracker {
    fs.default.name PARENT:ATTRIB fs.default.name;
    mapred.job.tracker LAZY PARENT:ATTRIB mapred.job.tracker;
    //yes, this is milliseconds. But there is a sleep involved too
    mapred.task.tracker.connect.timeout ORPHAN_CONNECT_TIMEOUT;

    //"ipc.client.connect.max.retries"
    ipc.client.connect.max.retries ORPHAN_CONNECT_MAX_RETRIES;
    
  }
}




/**
Test sequence that checks that when a namenode is shut down, it goes away
*/
NamenodeShutdownSequence extends Sequence {
  namenode TBD;

  waitForNameNode extends WaitForServiceLive {
    serviceName "namenode";
    service LAZY PARENT:namenode;
  }


  //detach and terminate
  terminateNameNode extends Terminator {
    kill LAZY PARENT:namenode;
    detachFirst true;
  }

  //now assert that it is dead
  assertIPCClosed extends AssertNameNodeIPCClosed;
  assertHttpClosed extends AssertNameNodeHttpClosed;
}

FileSystemLiveSequence extends Sequence {

    namenode TBD;
    datanode TBD;
    datanodeCount 1;
    //the cluster for all the tests
    cluster namenode;

    waitForNameNode extends WaitForNameNodeLive {
      service LAZY PARENT:namenode;
    }

    waitForDataNode extends WaitForDataNodeLive {
      service LAZY PARENT:datanode;
    }


}


/**
 * A sequence of operations on a cluster */
FileSystemTestSequence extends FileSystemLiveSequence {



    rootDirExists extends DfsDirExistsWorkflow {
      cluster LAZY PARENT:cluster;
      path "/";
      verbose true;
    }

    touch extends DfsCreateFileWorkflow {
      cluster LAZY PARENT:cluster;
      path "/test-filename";
      text "0123456789012345678901234567890123456789";
    }

    assertFileExists extends DfsFileExistsWorkflow {
      cluster LAZY PARENT:cluster;
      path touch:path;
      minSize 40;
      verbose true;
    }

    rootDirHasOneEntry extends rootDirExists {
      minFileCount 1;
      maxFileCount minFileCount;
      minTotalFileSize assertFileExists:minSize;
    }

  }

  FileCreation extends Compound  {
    cluster TBD;
    dest TBD;

    sfShouldTerminate true;

    sourceFile extends InlineTupleSource {
      data [
        ["one",43],
        ["two", "43"],
        ["one",12]
      ]

    }

    UploadHadoopCsvFile extends TuplesToHadoop {
      cluster LAZY PARENT:cluster;
      source LAZY sourceFile;
      dest testFile;
    }
  }

TestJob extends Job {
  name TBD;
  cluster TBD;
  jobTracker TBD;
  fs.default.name cluster:fs.default.name;
  testURL (fs.default.name ++ testDir);
  mapred.job.tracker jobTracker:mapred.job.tracker;
  hadoop.tmp.dir "/tmp";
  hadoop.tmp.URL (fs.default.name ++ hadoop.tmp.dir);
  jobTimeout JOB_TIMEOUT;

  //mapred.system.dir "/tmp/hadoop/mapred/system";

  //mapred.child.java.opts "-Xmx512m -d64 -server";
  mapred.tasktracker.map.tasks.maximum 5;
  mapred.tasktracker.reduce.tasks.maximum 1;
  mapred.working.dir (hadoop.tmp.URL ++ "/" ++ name ++ "/working");
  mapred.local.dir (hadoop.tmp.URL ++ "/" ++ name ++ "local");
  io.sort.record.percent 0.1F;
  mapred.input.dir (fs.default.name ++ testDirIn);
  mapred.output.dir (fs.default.name ++ testDirOut);
  mapred.working.dir (fs.default.name ++ testDirWorking);

  //hadoop.job.ugi ;
}

TestJobNoFile extends TestJob {

}


/**
 Component that sleeps for a limited period
 */
Sleep extends Delay {
  time STARTUP_SLEEP_TIME;
}


/**
 * this is a condition which is true only
 * if a lazy property test.fork.tests.enabled is set
 */
IsForkTestsSet extends IsPropertyTrue {
    property "test.fork.tests.enabled";
}

LocalClusterStatus extends ClusterStatus {
  jobTracker TBD;

  fs.default.name jobTracker:fs.default.name;
  mapred.job.tracker jobTracker;
  hadoop.job.ugi jobTracker:hadoop.job.ugi;
  sfShouldTerminate true;
  supportedFileSystem true;
}


/**
 * sequence that waits for the filesystem and job trackers
 */

JobTrackerSequence extends FileSystemLiveSequence {

  jobTracker TBD;
  taskTracker TBD;

  sleep extends Sleep;

  waitForTaskTracker extends WaitForServiceLive {
    serviceName "TaskTracker";
    service LAZY PARENT:taskTracker;
  }

  waitForJobTracker extends WaitForJobTrackerLive {
    service LAZY PARENT:jobTracker;
  }

/*  waitForFilesystem extends WaitForFilesystemLive {
    service LAZY PARENT:jobTracker;
    minCount datanodeCount;
  }*/

}

CountingFile extends TextFile {
    filename inputFileLocal;
    createParentDirs true;
    sfShouldTerminate true;
    text ##1,one,un,ein
2,two,deux,zwei
3,three,trois,drei
4,four,quatre,vier
5,five,cinq,funf#;
  }


CopyFileInAndOut extends FileSystemLiveSequence {

  testDir "/tests/CopyFileInAndOut";
  testDirIn  (testDir ++ "/in");
  testDirOut (testDir ++ "/out");
  testDirWorking (testDir ++ "/working");
  testFile (testDirIn ++ "/in.txt");
  inputFileDFS testFile;
  outputFileDFS ( testDirOut ++ "/in.txt");
  LocalDataDir PROPERTY test.work.dir;
  inputFileLocal (LocalDataDir  ++ "/in.txt")
  outputFileLocal (LocalDataDir  ++ "/out.txt")

  inputFile extends CountingFile;


  CopyDataIn extends DfsCopyFileInWorkflow {
    cluster LAZY PARENT:cluster;
    source inputFileLocal;
    dest testFile;
  }

  SourceExists extends DfsFileExistsWorkflow {
    cluster LAZY PARENT:cluster;
    path inputFileDFS;
    minSize 40;
  }

  lsIn extends DfsListDir {
    cluster LAZY PARENT:cluster;
    path  testDirIn;
  }

  ResultExists extends DfsFileExistsWorkflow {
    cluster LAZY PARENT:cluster;
    path testFile;
  }

  CopyDataOut extends DfsCopyFileOutWorkflow {
    cluster LAZY PARENT:cluster;
    source testFile;
    dest outputFileLocal;
  }

}

/**
 * this is a complete MR workflow
 */
JobTrackerSourceFileSequence extends JobTrackerSequence {

  fs.default.name cluster:fs.default.name;
  testURL (fs.default.name ++ testDir);
  testDir "/tests/mrtestsequence";
  testDirIn  (testDir ++ "/in");
  testDirOut (testDir ++ "/out");
  testDirWorking (testDir ++ "/working");
  testFile (testDirIn ++ "/in.txt");
  inputFileDFS testFile;
  outputFileDFS ( testDirOut ++ "/part-0000");
  LocalDataDir PROPERTY test.work.dir;
  inputFileLocal (LocalDataDir  ++ "/in.txt")
  outputDirLocal (LocalDataDir  ++ "/out")
  //outputFileLocal (LocalDataDir  ++ "/out.txt")

  mapred.job.tracker jobTracker:mapred.job.tracker;
  hadoop.tmp.dir "/tmp";
  hadoop.tmp.URL (fs.default.name ++ hadoop.tmp.dir);
  jobTimeout JOB_TIMEOUT;

  //mapred.system.dir "/tmp/hadoop/mapred/system";

  //mapred.child.java.opts "-Xmx512m -d64 -server";
  mapred.tasktracker.map.tasks.maximum 5;
  mapred.tasktracker.reduce.tasks.maximum 1;

  io.sort.record.percent 0.1F;
  mapred.input.dir (fs.default.name ++ testDirIn);
  mapred.output.dir (fs.default.name ++ testDirOut);
  mapred.working.dir (fs.default.name ++ testDirWorking);

  inputFile extends CountingFile;

  CopyDataIn extends DfsCopyFileInWorkflow {
    cluster LAZY PARENT:cluster;
    source inputFileLocal;
    dest testFile;
  }

  SourceExists extends DfsFileExistsWorkflow {
    cluster LAZY PARENT:cluster;
    path inputFileDFS;
    minSize 40;
  }

  lsIn extends DfsListDir {
    cluster LAZY PARENT:cluster;
    path  testDirIn;
  }

  mkOutputDir extends DfsCreateDir {
    cluster LAZY PARENT:cluster;
    path  testDirOut;
  }

/*
  DestDirExists extends DfsDirExistsWorkflow {
    cluster LAZY PARENT:cluster;
    path testDirOut;
    maxFileCount 0;
  }

*/

}

MapReduceTestSequence extends JobTrackerSourceFileSequence {

  job extends TestJob {
    mapred.mapper.new-api true;
    cluster LAZY PARENT:cluster;
    jobTracker LAZY PARENT:jobTracker;
    results LAZY PARENT;
    name "testsubmission";
    fs.default.name PARENT:fs.default.name;
    mapred.input.dir PARENT:mapred.input.dir;
    mapred.output.dir PARENT:mapred.output.dir;
    //mapred.working.dir PARENT:mapred.working.dir;
    //mapred.local.dir PARENT:mapred.local.dir;
    mapred.mapper.new-api true;
    //mapred.job.split.file (testDir ++ "/split");
    mapred.job.tracker jobTracker:mapred.job.tracker;

    mapred.working.dir (hadoop.tmp.URL ++ "/" ++ name ++ "/working");
    mapred.local.dir (hadoop.tmp.URL ++ "/" ++ name ++ "local");

    keep.failed.task.files true;
    filename "";
    fileRequired false;
    mapred.jar NULL;
    mapred.map.max.attempts 1;
    mapred.reduce.max.attempts 1;
  }

  s1 extends Sleep;


  lsOut extends DfsListDir {
    cluster LAZY PARENT:cluster;
    path  mapred.output.dir;
  }

  OutDirHasOneFile extends DfsDirExistsWorkflow {
    cluster LAZY PARENT:cluster;
    path mapred.output.dir;
    minFileCount 1;
    verbose true;
  }

/*
  ResultExists extends DfsFileExistsWorkflow {
    cluster LAZY PARENT:cluster;
    path outputFileDFS;
    minSize 40;
  }
*/

  CopyDataOut extends DfsCopyFileOutWorkflow {
    cluster LAZY PARENT:cluster;
    source mapred.output.dir;
    dest outputDirLocal;
  }

}



