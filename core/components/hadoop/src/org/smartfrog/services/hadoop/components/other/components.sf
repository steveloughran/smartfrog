/* (C) Copyright 2008 Hewlett-Packard Development Company, LP

This library is free software; you can redistribute it and/or
modify it under the terms of the GNU Lesser General Public
License as published by the Free Software Foundation; either
version 2.1 of the License, or (at your option) any later version.

This library is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public
License along with this library; if not, write to the Free Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

For more information: www.smartfrog.org

*/

/**
 * This class deploys Hadoop's Mock Service, so as to test out lifecycle handling
 * and other aspects of cluster failure. It is very much a test component
 */
 
MockService extends ClusterNode {
  sfClass "org.smartfrog.services.hadoop.components.other.MockServiceImpl";
  failOnStart false;
  failOnPing false;
  failOnClose false;
}

/**
 * This checks service values
 */
ServiceValueChecker extends Prim {
  sfClass "org.smartfrog.services.hadoop.components.other.ServiceValueCheckerImpl"
  expectNodeTermination false;
  expectedValues [];
}

CheckJspClasses extends LoadClass {

  classes [
   classname
   ];
  create false;
  retain false;
  message "Failed to load a JSP class. These may not have been compiled in correctly";
  sfShouldTerminate true;

  nn_jsphelper "org.apache.hadoop.hdfs.server.namenode.JspHelper";
  nn_dfshealth "org.apache.hadoop.hdfs.server.namenode.dfshealth_jsp";
  nn_dfsnodelist"org.apache.hadoop.hdfs.server.namenode.dfsnodelist_jsp";
  dn_browseBlock   "org.apache.hadoop.hdfs.server.datanode.browseBlock_jsp";
  dn_browseDirectory   "org.apache.hadoop.hdfs.server.datanode.browseDirectory_jsp";
  dn_tail "org.apache.hadoop.hdfs.server.datanode.tail_jsp";
  jt_analyseJobHistory  "org.apache.hadoop.mapred.analysejobhistory_jsp";
  tt_tasktracker  "org.apache.hadoop.mapred.tasktracker_jsp";
}


CheckJasperClasses extends CheckJspClasses {
  message "Redistributatle JSP classes found in jasper JAR files";
  classes [
    "javax.servlet.http.HttpServletRequest",
    "org.apache.jasper.runtime.HttpJspBase",
    "org.apache.jasper.runtime.JspSourceDependent",
    "javax.servlet.jsp.JspWriter"
  ];
}

HadoopJspClasses extends CheckJspClasses {
   message "JSP Pages from Hadoop that are pre-compiled into Java binaries";
   classes [
    nn_dfshealth,
    nn_dfsnodelist,
    dn_browseBlock,
    dn_browseDirectory,
    dn_tail,
    jt_analyseJobHistory,
    tt_tasktracker  
    ];
}

HadoopResourceCheck extends LoadClass {
  message "Failed to load a Hadoop resource that is required";
  resources [
   ];
  create false;
  retain false;
  sfShouldTerminate true;
}

HadoopDefaultResources extends HadoopResourceCheck {
  resources [
    "core-default.xml",
    "hdfs-default.xml",
    "mapred-default.xml"
   ];
}

HadoopSiteResources extends HadoopResourceCheck {
  resources [
    "core-site.xml",
    "hdfs-site.xml",
    "mapred-site.xml"
   ];
}

CheckJspHelperClasses extends CheckJspClasses {
    message "JspHelper and imports";
    classes [
    "java.util.zip.GZIPInputStream",
    "java.util.zip.GZIPOutputStream",
    "javax.servlet.http.HttpServletRequest",
    "javax.servlet.jsp.JspWriter",
    "org.apache.commons.logging.Log",
    "org.apache.commons.logging.LogFactory",
    "org.apache.log4j.Logger",
    "org.w3c.dom.DOMException",
    "org.w3c.dom.Document",
    "org.w3c.dom.Element",
    "org.w3c.dom.Node",
    "org.w3c.dom.NodeList",
    "org.w3c.dom.Text",
    "org.xml.sax.SAXException",
    "org.apache.hadoop.util.ReflectionUtils",
    "org.apache.hadoop.io.DataInputBuffer",
    "org.apache.hadoop.io.DataOutputBuffer",
    "org.apache.hadoop.io.Writable",
    "org.apache.hadoop.io.serializer.Deserializer",
    "org.apache.hadoop.io.serializer.SerializationFactory",
    "org.apache.hadoop.io.Writable",
    "org.apache.hadoop.io.WritableUtils",
    "org.apache.hadoop.util.StringUtils",
    "org.apache.hadoop.fs.Path",
    "org.apache.hadoop.fs.ContentSummary",
    "org.apache.hadoop.fs.FileStatus",
    "org.apache.hadoop.fs.permission.FsAction",
    "org.apache.hadoop.fs.permission.FsPermission",
    "org.apache.hadoop.fs.permission.PermissionStatus",
    "org.apache.hadoop.hdfs.DFSUtil",
    "org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException",
    "org.apache.hadoop.hdfs.protocol.Block",
    "org.apache.hadoop.hdfs.protocol.BlockListAsLongs",
    "org.apache.hadoop.hdfs.protocol.ClientProtocol",
    "org.apache.hadoop.hdfs.protocol.DatanodeID",
    "org.apache.hadoop.hdfs.protocol.DatanodeInfo",
    "org.apache.hadoop.hdfs.protocol.FSConstants",
    "org.apache.hadoop.hdfs.protocol.LocatedBlock",
    "org.apache.hadoop.hdfs.protocol.LocatedBlocks",
    "org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException",
    "org.apache.hadoop.hdfs.server.common.GenerationStamp",
    "org.apache.hadoop.hdfs.server.common.HdfsConstants$StartupOption",
    "org.apache.hadoop.hdfs.server.common.Storage",
    "org.apache.hadoop.hdfs.server.common.UpgradeStatusReport",
    "org.apache.hadoop.hdfs.server.namenode.BlocksMap",
    "org.apache.hadoop.hdfs.server.namenode.LeaseManager",
    "org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean",
    "org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics",
    "org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations",
    "org.apache.hadoop.hdfs.server.protocol.DatanodeCommand",
    "org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration",
    "org.apache.hadoop.hdfs.server.protocol.DisallowedDatanodeException",
    "org.apache.hadoop.hdfs.server.protocol.NamespaceInfo",
    "org.apache.hadoop.hdfs.server.protocol.UpgradeCommand",
    "org.apache.hadoop.io.IOUtils",
    "org.apache.hadoop.ipc.Server",
    "org.apache.hadoop.metrics.util.MBeanUtil",
    "org.apache.hadoop.net.CachedDNSToSwitchMapping",
    "org.apache.hadoop.net.DNSToSwitchMapping",
    "org.apache.hadoop.net.NetworkTopology",
    "org.apache.hadoop.net.ScriptBasedMapping",
    "org.apache.hadoop.security.AccessControlException",
    "org.apache.hadoop.security.UnixUserGroupInformation",
    "org.apache.hadoop.security.UserGroupInformation",
    "org.apache.hadoop.util.Daemon",
    "org.apache.hadoop.util.HostsFileReader",
    "org.apache.hadoop.util.ReflectionUtils",
    "org.apache.hadoop.util.StringUtils",
    "org.apache.hadoop.hdfs.server.namenode.FSNamesystem",
    "org.apache.hadoop.conf.Configured",
    "org.apache.hadoop.conf.Configuration",
    "org.apache.hadoop.hdfs.DFSClient",
    "org.apache.hadoop.hdfs.protocol.DatanodeID",
    "org.apache.hadoop.hdfs.protocol.DatanodeInfo",
    "org.apache.hadoop.hdfs.protocol.LocatedBlock",
    "org.apache.hadoop.hdfs.protocol.FSConstants",
    "org.apache.hadoop.hdfs.server.common.HdfsConstants",
    "org.apache.hadoop.hdfs.server.common.UpgradeStatusReport",
    "org.apache.hadoop.hdfs.server.datanode.DataNode",
    "org.apache.hadoop.fs.Path",
    "org.apache.hadoop.util.StringUtils",
    "org.apache.hadoop.net.NetUtils",
    "org.apache.hadoop.security.UnixUserGroupInformation",
    "org.apache.hadoop.conf.Configuration",
    "org.apache.hadoop.hdfs.HDFSPolicyProvider",
    "org.apache.hadoop.hdfs.protocol.Block",
    "org.apache.hadoop.hdfs.protocol.BlockListAsLongs",
    "org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol",
    "org.apache.hadoop.hdfs.protocol.DataTransferProtocol",
    "org.apache.hadoop.hdfs.protocol.DatanodeID",
    "org.apache.hadoop.hdfs.protocol.DatanodeInfo",
    "org.apache.hadoop.hdfs.protocol.FSConstants",
    "org.apache.hadoop.hdfs.protocol.LocatedBlock",
    "org.apache.hadoop.hdfs.protocol.UnregisteredDatanodeException",
    "org.apache.hadoop.hdfs.server.common.HdfsConstants",
    "org.apache.hadoop.hdfs.server.common.GenerationStamp",
    "org.apache.hadoop.hdfs.server.common.IncorrectVersionException",
    "org.apache.hadoop.hdfs.server.common.Storage",
    "org.apache.hadoop.hdfs.server.datanode.metrics.DataNodeMetrics",
    "org.apache.hadoop.hdfs.server.namenode.FSNamesystem",
    "org.apache.hadoop.hdfs.server.namenode.FileChecksumServlets",
    "org.apache.hadoop.hdfs.server.namenode.NameNode",
    "org.apache.hadoop.hdfs.server.namenode.StreamFile",
    "org.apache.hadoop.hdfs.server.protocol.BlockCommand",
    "org.apache.hadoop.hdfs.server.protocol.BlockMetaDataInfo",
    "org.apache.hadoop.hdfs.server.protocol.DatanodeCommand",
    "org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol",
    "org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration",
    "org.apache.hadoop.hdfs.server.protocol.DisallowedDatanodeException",
    "org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol",
    "org.apache.hadoop.hdfs.server.protocol.NamespaceInfo",
    "org.apache.hadoop.hdfs.server.protocol.UpgradeCommand",
    "org.apache.hadoop.http.HttpServer",
    "org.apache.hadoop.io.IOUtils",
    "org.apache.hadoop.io.Text",
    "org.apache.hadoop.ipc.RPC",
    "org.apache.hadoop.ipc.RemoteException",
    "org.apache.hadoop.ipc.Server",
    "org.apache.hadoop.net.DNS",
    "org.apache.hadoop.net.NetUtils",
    "org.apache.hadoop.security.SecurityUtil",
    "org.apache.hadoop.security.authorize.ConfiguredPolicy",
    "org.apache.hadoop.security.authorize.PolicyProvider",
    "org.apache.hadoop.security.authorize.ServiceAuthorizationManager",
    "org.apache.hadoop.util.Daemon",
    "org.apache.hadoop.util.DiskChecker",
    "org.apache.hadoop.util.ReflectionUtils",
    "org.apache.hadoop.util.StringUtils",
    "org.apache.hadoop.util.DiskChecker$DiskErrorException",
    "org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException",
    "org.apache.hadoop.util.Service",
    "org.apache.hadoop.hdfs.DFSUtil",
    "org.apache.hadoop.hdfs.server.common.GenerationStamp",
    "org.apache.hadoop.hdfs.server.common.HdfsConstants",
    "org.apache.hadoop.hdfs.server.common.Storage",
    "org.apache.hadoop.hdfs.server.common.UpgradeStatusReport",
    "org.apache.hadoop.hdfs.server.namenode.BlocksMap",
    "org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMBean",
    "org.apache.hadoop.hdfs.server.namenode.metrics.FSNamesystemMetrics",
    "org.apache.hadoop.security.AccessControlException",
    "org.apache.hadoop.security.UnixUserGroupInformation",
    "org.apache.hadoop.security.UserGroupInformation",
    "org.apache.hadoop.metrics.util.MBeanUtil",
    "org.apache.hadoop.net.CachedDNSToSwitchMapping",
    "org.apache.hadoop.net.DNSToSwitchMapping",
    "org.apache.hadoop.net.NetworkTopology",
    "org.apache.hadoop.net.ScriptBasedMapping",
    "org.apache.hadoop.hdfs.server.namenode.LeaseManager$Lease",
    "org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations",
    "org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations$BlockWithLocations",
    "org.apache.hadoop.hdfs.server.protocol.DatanodeCommand",
    "org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration",
    "org.apache.hadoop.hdfs.server.protocol.DisallowedDatanodeException",
    "org.apache.hadoop.hdfs.server.protocol.NamespaceInfo",
    "org.apache.hadoop.hdfs.server.protocol.UpgradeCommand",
    "org.apache.hadoop.fs.ContentSummary",
    "org.apache.hadoop.fs.FileStatus",
    "org.apache.hadoop.fs.Path",
    "org.apache.hadoop.ipc.Server",
    "org.apache.hadoop.io.IOUtils",

    nn_jsphelper
    ];
}

CheckNamenodeJspClasses extends CheckJspClasses {
     classes [
    "javax.servlet.http.HttpServletRequest",
    "javax.servlet.jsp.JspWriter",
    "org.apache.hadoop.conf.Configuration",
    "org.apache.hadoop.hdfs.DFSClient",
    "org.apache.hadoop.hdfs.protocol.DatanodeID",
    "org.apache.hadoop.hdfs.protocol.DatanodeInfo",
    "org.apache.hadoop.hdfs.protocol.LocatedBlock",
    "org.apache.hadoop.hdfs.protocol.FSConstants",
    "org.apache.hadoop.hdfs.server.common.HdfsConstants",
    "org.apache.hadoop.hdfs.server.common.UpgradeStatusReport",
    "org.apache.hadoop.hdfs.server.datanode.DataNode",
    "org.apache.hadoop.fs.Path",
    "org.apache.hadoop.util.StringUtils",
    "org.apache.hadoop.net.NetUtils",
    "org.apache.hadoop.security.UnixUserGroupInformation",
    nn_jsphelper,
    nn_dfshealth,
    nn_dfsnodelist
    ];

}

CheckDatanodeJspClasses extends CheckJspClasses {
  classname dn_browseBlock;
}

CheckJobtrackerJspClasses extends CheckJspClasses {
  classname jt_analyseJobHistory;
}



/**
 * helper component to check that we can load JSP classes
 */
CheckJava6PlusClassesPresent extends LoadClass {
  classes [
   "java.net.CookieManager"
   ];
  create false;
  retain false;
  message "Failed to load a Java 6 class. Hadoop requires Java 6 or later";
  sfShouldTerminate true;
}

