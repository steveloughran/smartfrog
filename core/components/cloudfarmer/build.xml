<?xml version="1.0" encoding="utf-8"?>
<project name="cloudfarmer" default="default">

  <!--
  /** (C) Copyright 2009 Hewlett-Packard Development Company, LP

  This library is free software; you can redistribute it and/or
  modify it under the terms of the GNU Lesser General Public
  License as published by the Free Software Foundation; either
  version 2.1 of the License, or (at your option) any later version.

  This library is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
  Lesser General Public License for more details.

  You should have received a copy of the GNU Lesser General Public
  License along with this library; if not, write to the Free Software
  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

  For more information: www.smartfrog.org

  */
  -->

  <description>
    This provides 
     * the base CloudFarmer API and the mock and manual implementations.
     * the web, SF component and ant clients
    Other CloudFarmer implementations are with the back ends 
  </description>

  <!--

  This build does a bit of a trick in that it has a subdir called site/ in the root directory.

  This directory is copied into the source tree under org/smartfrog/services/cloudfarmer/client/web

  Why this layout?
  * makes it easy for the IDEs to handle things
  * we want the site in the JAR for Jetty
  * gives us the option in future of creating a WAR file based on site/


  -->

  <!--we are a component -->
  <property name="is.component" value="true"/>
  <property name="ivy.enabled" value="true"/>

  <!-- override point -->
  <property file="build.properties"/>
<!--  <property name="system.tests" value="true"/>-->
  <!--very long test timeout to allow for startup delays-->
  <property name="test.timeout.execute" value="120000" />
  <property name="test.timeout.startup" value="${test.timeout.execute}" />
  <property name="site.dir" location="site" />
  <property name="test.web.dir" location="${site.dir}" />
  <!--<property name="application.name" value="ec2" />-->
  <property name="mockfarmer.sf" value="/org/smartfrog/services/cloudfarmer/server/mock/example.sf" />
  <property name="localfarmer.sf" value="/org/smartfrog/services/cloudfarmer/server/examples/localhost_over_ssh.sf" />
  <property name="mombasa.sf" value="/org/smartfrog/services/cloudfarmer/client/web/deploy/server.sf" />
  
  <!--test port and host-->
  <property name="test.mombasa.host" value="localhost" />
  <property name="test.mombasa.port" value="8081" />
  <property name="test.mombasa.url" value="http://${test.mombasa.host}:${test.mombasa.port}/" />
  <property name="test.hadoop-site.xml" value="${test.mombasa.url}hadoop-site.xml" />
  <property name="test.cluster.properties" value="${test.mombasa.url}hosts.properties?prefix=test.cluster" />


  <!-- <property name="deploy.sf" value="${mombasa.sf}" />-->

  <echo message="==================================================================="/>
  <echo message="= ${ant.project.name}"/>

  <!-- Import common stuff -->
  <import file="../../common.xml"/>

  <target name="ready-to-jar" depends="common.ready-to-jar,copy-site" />


  <target name="copy-site" depends="init">
    <property name="site.target.package" value="/org/smartfrog/services/cloudfarmer/client/web/site"/>
    <property name="site.target.dir" location="${build.classes.dir}${site.target.package}" />
    <mkdir  dir="${site.target.dir}"/>

    <copy todir="${site.target.dir}" >
       <fileset dir="site" />
    </copy>
    </target>


  <target name="ready-to-test" depends="common.ready-to-test">
    <echo level="verbose">
      system.tests=${system.tests}
    </echo>
  </target>

  
  <target  name="mockfarmer" depends="ready-to-deploy"
       description="Deploy a mock farm manager" >
      <deploy>
        <application name="farmer"
            descriptor="${mockfarmer.sf}"/>
      </deploy>
  </target>

  <target  name="localfarmer" depends="ready-to-deploy"
      description="Deploy a farm manager that serves up the local host" >
    <deploy>
      <application name="farmer"
          descriptor="${localfarmer.sf}"/>
    </deploy>
  </target>
  
  <target name="localfarmerssh" depends="ready-to-deploy"
      description="Deploy a farm manager that serves up the local hostover SSH" >
    <deploy>
      <application name="farmer"
          descriptor="/org/smartfrog/services/cloudfarmer/server/examples/localhost_over_ssh.sf"/>
    </deploy>
  </target>
  
  <target  name="mombasa" depends="ready-to-deploy"
       description="Deploy the mombasa web application" >
      <deploy>
        <application name="mombasa"
            descriptor="${mombasa.sf}"/>
      </deploy>
  </target>

  <target  name="mockmombasa" depends="mombasa, mockfarmer"
       description="Deploy a mock farm manager and the client web application" >
  </target>

  <target  name="mombasacompound" depends="ready-to-deploy"
      description="Deploy the applications in a compound" >
    <deploy>
      <application name="mombasa"
          descriptor="/org/smartfrog/services/cloudfarmer/client/web/deploy/mockmombasa.sf"/>
    </deploy>
  </target>
  

  <target  name="forkedcluster" depends="ready-to-deploy"
      description="Deploy a forked Hadoop cluster against a local farmer" >
    <deploy>
      <application name="forkedcluster"
          descriptor="/org/smartfrog/services/cloudfarmer/server/examples/forkedhadoopcustomer.sf"/>
    </deploy>
  </target>

  <!-- ========================================================== -->
  <!-- start the daemon in the foreground                         -->
  <!-- ========================================================== -->
  <target name="start-daemon-fg"
      description="start a daemon in the foreground"
      depends="declare-extended-smartfrog-tasks"
      >
    <sf-startdaemon-debug  spawn="false" timeout="-1">
      <application name="mombasa"
          descriptor="${mombasa.sf}"/>
      <application name="farmer"
          descriptor="${mockfarmer.sf}"/>
    </sf-startdaemon-debug>
  </target>

  <target name="ready-to-get" depends="init">
    <property name="hadoop.config.dir" location="${build.dir}/hadoop-config" />
    <mkdir dir="${hadoop.config.dir}" />
    <property name="hadoop.site.xml" location="${hadoop.config.dir}/hadoop-site.xml" />
    <property name="cluster.properties" location="${hadoop.config.dir}/cluster.properties" />  
    <property name="remote.dir" value="/root" />
    <property name="remote.settings.dir" value="${remote.dir}/settings" />
    <property name="init-classpath" value='source setSFProperties; export CLASSPATH="${remote.settings.dir}:$CLASSPATH"'/>
  </target>

  <target name="GET" depends="ready-to-get"
      description="fetch the mombasa cluster list">
    <echo> fetching ${test.hadoop-site.xml} to ${hadoop.site.xml}</echo>
    <get src="${test.mombasa.url}mombasa-portlet/cluster/list.do"
        dest="${hadoop.config.dir}/host-list.html" />
  </target>

  <target name="hadoop-site.xml" depends="ready-to-get" 
      description="fetch the hadoop site from the farmer">
    <echo> fetching ${test.hadoop-site.xml} to ${hadoop.site.xml}</echo>
    <get src="${test.hadoop-site.xml}"
      dest="${hadoop.site.xml}" />
  </target>

  <target name="cluster.properties" depends="ready-to-get"
      description="cluster properties">
    <echo> fetching ${test.hadoop-site.xml} to ${hadoop.site.xml}</echo>
    <get src="${test.cluster.properties}"
        dest="${cluster.properties}" />
    <property file="${cluster.properties}" />
  </target>

  <target name="cluster-bind" depends="cluster.properties, hadoop-site.xml" >
    <fail unless="test.cluster.role.master.1" >
      No cluster master found: has anything been deployed?
    </fail>
    <property name="cluster.master" value="${test.cluster.role.master.1}" />
    <echo > working with ${cluster.master}</echo>
  </target>

  <target name="cluster-upload-settings" depends="cluster-bind, hadoop-site.xml" >
    <sshexec host="${cluster.master}"
        username="root"
        trust="true"
        password="${test.cluster.password}"
        command="rm -rf ${remote.settings.dir} ${remote.dir}/in ${remote.dir}/out; mkdir ${remote.settings.dir}"/>
    <!--verbose="true"-->
    <scp file="${hadoop.site.xml}"
        todir="root@${cluster.master}:${remote.settings.dir}"
        trust="true"
        password="${test.cluster.password}"
        />
  </target>
  
  <target name="terasort" depends="cluster-upload-settings" >
    <property name="terasort.size" value="10000000" />
    <echo>
Now:
ssh root@${cluster.master}
      
${init-classpath}
rm -rf in out
time java org.apache.hadoop.util.RunJar $SFHOME/lib/hadoop-mapred-examples-*.jar teragen ${terasort.size} in -verbose
time java -Xmx1024m org.apache.hadoop.util.RunJar $SFHOME/lib/hadoop-mapred-examples-*.jar terasort in out -verbose
    </echo>
  </target>
  
  
  <target  name="job-queue" depends="cluster-bind">
    <property name="jobqueue" value="org.apache.hadoop.mapred.JobQueueClient"/>
    <property name="jobqueue.commands" value="-list -showjobs"/>
    <!--
    <property name="jobqueue.commands" value="-list -showjobs  -verbose"/>
    -->
    <sshexec host="${cluster.master}"
        username="root"
        trust="true"
        password="${test.cluster.password}"
        command='${init-classpath}; java ${jobqueue} ${jobqueue.commands}'/>
  </target>

    
    <!--
    ssh ${cluster.master}
    mkdir /root/settings
    scp build/hadoop-config/hadoop-site.xml root@${cluster.master}:/root/settings/hadoop-site.xml


    scp build/hadoop-config/hadoop-site.xml root@masterc0-vif0.cell-9b367ca2.ext9.sup.hpl.hp.com:/root/settings/hadoop-site.xml
    
    
        The CP has to be set up with all the Hadoop JARS (simplest, SF_HOME/*.jar
    
    
    source setSFProperties
    export CLASSPATH="/root/settings:$CLASSPATH"
    echo $CLASSPATH
    
    the main class in the examples file runs the ExampleDriver which takes the example name as param #1, 
    the command to it is:
     
    java -classpath CLASSPATH
      org.apache.hadoop.util.RunJar
      hadoop-mapred-examples-0.22.0-alpha-3.jar
      terasort  
      in-dir
      out-dir
    
    
    creating the test data. Does not need a live test-runner
    
    <property name="terasort.size" value="100000000" />
    rm -rf in
    java org.apache.hadoop.util.RunJar $SFHOME/lib/hadoop-mapred-examples-*.jar teragen 100000000 in -verbose
    rm -rf out
    time java -Xmx1024m org.apache.hadoop.util.RunJar $SFHOME/lib/hadoop-mapred-examples-*.jar terasort in out
    

    -->
  
</project>